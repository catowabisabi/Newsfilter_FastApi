"""
é«˜é€ŸNewsFilteræœå‹™
æ•´åˆæ–°APIã€ç·©å­˜ã€MongoDBæ•¸æ“šåº«å’ŒChatGPTç¿»è­¯åŠŸèƒ½
"""

import requests
import json
import time
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import os
import sys
from dotenv import load_dotenv

# åŠ è¼‰ç’°å¢ƒè®Šé‡
load_dotenv()

from app.services.newsfilter_auth import NewsFilterAuth
from app.database.sqlite_cache import SQLiteCacheManager
from app.database.mongodb_manager import MongoDBManager
from app.utils.news_analyzer import NewsAnalyzer
from app.utils.chatgpt_translator import ChatGPTTranslator


class SuperFastNewsService:
    """è¶…é«˜é€ŸNewsFilteræœå‹™"""
    
    def __init__(self):
        self.api_url = os.getenv("NEWSFILTER_API_URL", "https://api.newsfilter.io/actions")
        
        # åˆå§‹åŒ–å„å€‹çµ„ä»¶
        self.auth = NewsFilterAuth()
        self.sqlite_cache = SQLiteCacheManager()
        
        # MongoDBé€£æ¥ï¼ˆå¸¶éŒ¯èª¤è™•ç†ï¼‰
        self.mongodb = None
        self._init_mongodb()
        
        # ChatGPTç¿»è­¯å™¨
        self.translator = ChatGPTTranslator()
        
        # æ–°èåˆ†æå™¨
        self.news_analyzer = NewsAnalyzer()
        
        self.request_timeout = 30
        
        print("ğŸš€ SuperFast NewsFilter Service initialized")
    
    def _init_mongodb(self):
        """åˆå§‹åŒ–MongoDBé€£æ¥ï¼Œå¸¶éŒ¯èª¤è™•ç†"""
        try:
            self.mongodb = MongoDBManager()
            if self.mongodb.client is None:
                print("âš ï¸ MongoDB connection failed, running without database persistence")
                self.mongodb = None
        except Exception as e:
            print(f"âš ï¸ MongoDB initialization error: {e}")
            print("âš ï¸ Running without MongoDB - data will only be cached locally")
            self.mongodb = None
    
    async def get_symbol_news(self, symbol: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ç²å–æŒ‡å®šè‚¡ç¥¨çš„æ–°è
        
        æŸ¥æ‰¾é †åºï¼š
        1. SQLiteç·©å­˜ï¼ˆ1å°æ™‚å…§ï¼‰
        2. MongoDBæ•¸æ“šåº«
        3. NewsFilter API
        
        å¦‚æœæœ‰éŒ¯èª¤ï¼Œè¿”å› [{"msg": "error message"}]
        """
        
        try:
            symbol = symbol.upper()
            
            # æª¢æŸ¥æ˜¯å¦è™•æ–¼ç™»éŒ„å¤±æ•—ç‹€æ…‹
            if self.auth.is_login_failed:
                remaining_time = self.auth.get_remaining_sleep_time()
                if remaining_time > 0:
                    return [{"msg": "NewsFilter Fail"}]
            
            # 1. å…ˆæª¢æŸ¥SQLiteç·©å­˜
            print(f"ğŸ” Checking cache for {symbol}...")
            cached_articles = self.sqlite_cache.get_news_cache(symbol, limit)
            
            if cached_articles:
                print(f"âœ… Found {len(cached_articles)} articles in cache")
                return await self._process_articles(cached_articles, symbol)
            
            # 2. æª¢æŸ¥MongoDB
            if self.mongodb:
                print(f"ğŸ” Checking MongoDB for {symbol}...")
                db_articles = self.mongodb.get_news_articles(symbol, limit)
                
                if db_articles:
                    print(f"âœ… Found {len(db_articles)} articles in MongoDB")
                    # ä¿å­˜åˆ°ç·©å­˜
                    self.sqlite_cache.save_news_cache(symbol, db_articles)
                    return await self._process_articles(db_articles, symbol)
            
            # 3. å¾NewsFilter APIç²å–
            print(f"ğŸ” Fetching from NewsFilter API for {symbol}...")
            api_articles = await self._fetch_from_api(symbol, limit)
            
            if not api_articles:
                print(f"ğŸ“­ No articles found for {symbol}")
                return []
            
            # ä¿å­˜åˆ°ç·©å­˜å’Œæ•¸æ“šåº«
            self.sqlite_cache.save_news_cache(symbol, api_articles)
            if self.mongodb:
                self.mongodb.save_news_articles(symbol, api_articles)
            
            # è™•ç†ä¸¦è¿”å›
            return await self._process_articles(api_articles, symbol)
            
        except Exception as e:
            print(f"âŒ Error in get_symbol_news: {e}")
            return [{"msg": f"Error: {str(e)}"}]
    
    async def _fetch_from_api(self, symbol: str, limit: int) -> List[Dict[str, Any]]:
        """ä»NewsFilter APIè·å–æ–°é—» (å¼‚æ­¥éé˜»å¡ç‰ˆæœ¬)"""
        
        # å°†é˜»å¡çš„requestsè°ƒç”¨æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ
        import asyncio
        loop = asyncio.get_running_loop()
        
        def _sync_request():
            """åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œçš„åŒæ­¥è¯·æ±‚é€»è¾‘"""
            headers = self.auth.get_auth_headers()
            if not headers:
                return []
            
            # ä½¿ç”¨æ›´å¹¿æ³›çš„æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ŒåŒ¹é…æ ‡é¢˜ã€æè¿°æˆ–ä»£ç 
            search_query = f'title:"{symbol}" OR description:"{symbol}" OR symbols:"{symbol}"'
            
            payload = {
                "type": "filterArticles",
                "isPublic": False,
                "queryString": search_query,
                "from": 0,
                "size": 50  # æ¢å¤å›ºå®š50ä¸ªï¼Œå¦‚ç”¨æˆ·æä¾›çš„ç¤ºä¾‹
            }
            
            try:
                # Rate limiting
                time.sleep(0.5)  # 500mså»¶è¿Ÿé¿å…429é”™è¯¯
                
                print(f"DEBUG: Payload for {symbol}: {json.dumps(payload)}")
                # print(f"DEBUG: Headers: {str(headers)[:50]}...")
                
                response = requests.post(
                    self.api_url,
                    headers=headers,
                    json=payload,
                    timeout=self.request_timeout
                )
                
                if response.status_code == 200:
                    data = response.json()
                    # print(f"DEBUG: Response data keys: {data.keys()}")
                    articles = data.get("articles", [])
                    
                    if articles:
                        print(f"âœ… API returned {len(articles)} articles for {symbol}")
                        # æˆªå–ç”¨æˆ·éœ€è¦çš„æ•°é‡
                        return articles[:limit] if limit < len(articles) else articles
                    else:
                        print(f"ğŸ“­ API returned no articles for {symbol}")
                        # å°è¯•é™çº§æŸ¥è¯¢ï¼šä»…æŸ¥è¯¢symbol
                        if 'OR' in search_query:
                            print(f"âš ï¸ Retrying with simple symbol query for {symbol}...")
                            time.sleep(1)
                            simple_payload = payload.copy()
                            simple_payload['queryString'] = symbol
                            retry_response = requests.post(
                                self.api_url,
                                headers=headers,
                                json=simple_payload,
                                timeout=self.request_timeout
                            )
                            if retry_response.status_code == 200:
                                retry_data = retry_response.json()
                                return retry_data.get("articles", [])
                        return []
                        
                elif response.status_code == 429:
                    print("â³ Rate limited by API")
                    return []
                    
                elif response.status_code == 401:
                    print("ğŸ”‘ Token invalid")
                    # åœ¨åŒæ­¥å‡½æ•°ä¸­æ— æ³•è°ƒç”¨å¼‚æ­¥çš„force_refresh_tokenï¼Œè¿™é‡Œç®€å•è¿”å›ç©º
                    # å¯ä»¥åœ¨å¤–å±‚å¤„ç†é‡è¯•é€»è¾‘
                    return []
                else:
                    print(f"âŒ API error: {response.status_code} - {response.text}")
                    return []
                    
            except Exception as e:
                print(f"âŒ API request exception: {e}")
                import traceback
                print(traceback.format_exc())
                return []

        # ä½¿ç”¨run_in_executoræ‰§è¡ŒåŒæ­¥å‡½æ•°
        return await loop.run_in_executor(None, _sync_request)
    
    async def _process_articles(self, articles: List[Dict[str, Any]], symbol: str) -> List[Dict[str, Any]]:
        """
        è™•ç†æ–‡ç« ï¼Œä½¿ç”¨ChatGPTç¿»è­¯ï¼Œä¿æŒèˆ‡åŸAPIç›¸åŒçš„æ ¼å¼
        å…ˆéæ¿¾10å¤©å¤–çš„æ–‡ç« ï¼Œå†ç¿»è­¯ï¼ˆé¿å…æµªè²»APIèª¿ç”¨ï¼‰
        """
        processed_articles = []
        loop = asyncio.get_running_loop()
        
        # ====== ç¬¬ä¸€æ­¥ï¼šå…ˆéæ¿¾10å¤©å¤–çš„æ–‡ç«  ======
        valid_articles = []
        for article in articles:
            try:
                item = self._convert_to_legacy_format(article, symbol)
                timestamp = item.get("timestamp", 0)
                if not self._is_within_days(timestamp, 10):
                    print(f"â° Skipping article older than 10 days: {item.get('title', 'N/A')[:50]}...")
                    continue
                valid_articles.append((article, item))
            except Exception as e:
                print(f"âš ï¸ Error converting article: {e}")
                continue
        
        if not valid_articles:
            print(f"ğŸ“­ No articles within 10 days for {symbol}")
            return []
        
        print(f"ğŸ“° {len(valid_articles)} articles within 10 days (filtered from {len(articles)})")
        
        # ====== ç¬¬äºŒæ­¥ï¼šç¿»è­¯æœ‰æ•ˆæ–‡ç«  ======
        articles_needing_update = []  # è¨˜éŒ„éœ€è¦æ›´æ–°åˆ°DBçš„æ–‡ç« 
        
        for original_article, item in valid_articles:
            try:
                # ä½¿ç”¨æœ¬åœ°åˆ†æå™¨é€²è¡Œé—œéµå­—åˆ†æ
                analyzed_result = self.news_analyzer.analyze(
                    item.get("title", ""), 
                    item.get("summary", "")
                )
                
                title = item.get("title", "")
                summary = item.get("summary", "")
                existing_title_cn = item.get("title_cn")
                existing_summary_cn = item.get("summary_cn")
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦ç¿»è­¯
                need_translate = not (existing_title_cn and existing_title_cn.strip() and existing_title_cn != title
                                     and existing_summary_cn and existing_summary_cn.strip() and existing_summary_cn != summary)
                
                if need_translate:
                    # éœ€è¦ç¿»è­¯ï¼Œèª¿ç”¨ChatGPT
                    title_cn, summary_cn = await loop.run_in_executor(
                        None, 
                        self.translator.translate_news, 
                        title, 
                        summary,
                        existing_title_cn,
                        existing_summary_cn
                    )
                    # è¨˜éŒ„éœ€è¦æ›´æ–°åˆ°DBçš„æ–‡ç« ï¼ˆå¸¶ç¿»è­¯çµæœï¼‰
                    articles_needing_update.append({
                        "original": original_article,
                        "title_cn": title_cn,
                        "summary_cn": summary_cn
                    })
                else:
                    # å·²æœ‰ç¿»è­¯ï¼Œç›´æ¥ä½¿ç”¨
                    title_cn = existing_title_cn
                    summary_cn = existing_summary_cn
                    print(f"âœ… Skip translation (already exists): {title[:40]}...")
                
                # æ§‹å»ºéŸ¿æ‡‰æ ¼å¼
                news_item = {
                    "title": title,
                    "title_cn": title_cn,
                    "summary": summary,
                    "summary_cn": summary_cn,
                    "timestamp": item.get("timestamp", 0),
                    "original_time": item.get("original_time", ""),
                    "source": item.get("source", ""),
                    "link": item.get("link", ""),
                    "tickers": item.get("tickers", [symbol]),
                    "type": item.get("type", "news"),
                    "score": analyzed_result.get("score", 0),
                    "keywords": analyzed_result.get("important_keywords", [])
                }
                
                processed_articles.append(news_item)
                
            except Exception as e:
                print(f"âš ï¸ Error processing article: {e}")
                continue
        
        # ====== ç¬¬ä¸‰æ­¥ï¼šæŠŠç¿»è­¯çµæœå¯«å›MongoDBå’ŒSQLiteç·©å­˜ ======
        if articles_needing_update:
            for update_item in articles_needing_update:
                original = update_item["original"]
                title_cn = update_item["title_cn"]
                summary_cn = update_item["summary_cn"]
                
                # æ›´æ–°åŸå§‹è³‡æ–™
                original["title_cn"] = title_cn
                original["summary_cn"] = summary_cn
                
                # æ›´æ–°SQLiteç·©å­˜
                try:
                    article_hash = self.sqlite_cache._generate_article_hash(original)
                    self.sqlite_cache.update_article_translation(article_hash, title_cn, summary_cn)
                except Exception as e:
                    print(f"âš ï¸ Error updating SQLite cache: {e}")
                
                # æ›´æ–°MongoDB
                if self.mongodb:
                    try:
                        article_hash = self.mongodb._generate_article_hash(original)
                        self.mongodb.collection.update_one(
                            {"article_hash": article_hash},
                            {"$set": {
                                "raw_data.title_cn": title_cn,
                                "raw_data.summary_cn": summary_cn,
                                "updated_at": datetime.utcnow()
                            }}
                        )
                    except Exception as e:
                        print(f"âš ï¸ Error updating MongoDB: {e}")
            
            print(f"ğŸ’¾ Updated {len(articles_needing_update)} translations to cache/DB")
        
        return processed_articles
    
    def _convert_to_legacy_format(self, article: Dict[str, Any], symbol: str) -> Dict[str, Any]:
        """
        å°†æ–°APIæ ¼å¼è½¬æ¢ä¸ºæ—§æ ¼å¼ï¼Œä»¥å…¼å®¹ç°æœ‰çš„news_handler
        ä¿ç•™å·²æœ‰çš„ title_cn / summary_cn é¿å…é‡è¤‡ç¿»è­¯
        """
        
        # æå–æ—¶é—´æˆ³
        published = article.get("publishedAt", "") or article.get("published", "")
        timestamp = self._parse_timestamp(published)
        
        # æå–æ¥æºä¿¡æ¯
        source_info = article.get("source", {})
        source_name = source_info.get("name", "Unknown") if isinstance(source_info, dict) else str(source_info)
        
        result = {
            "title": article.get("title", ""),
            "summary": article.get("description", "") or article.get("content", ""),
            "timestamp": timestamp,
            "original_time": published,
            "source": source_name,
            "link": article.get("url", ""),
            "tickers": [symbol],  # ä½¿ç”¨æŸ¥è¯¢çš„symbol
            "type": "news"
        }
        
        # ä¿ç•™å·²æœ‰çš„ä¸­æ–‡ç¿»è­¯ï¼ˆä¾†è‡ªç·©å­˜æˆ–MongoDBï¼‰
        if article.get("title_cn"):
            result["title_cn"] = article["title_cn"]
        if article.get("summary_cn"):
            result["summary_cn"] = article["summary_cn"]
        
        return result
    
    def _is_within_days(self, timestamp: int, days: int = 10) -> bool:
        """æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…"""
        if timestamp <= 0:
            return False  # æ— æ•ˆæ—¶é—´æˆ³
        
        try:
            current_time = time.time()
            time_diff = current_time - timestamp
            days_diff = time_diff / (24 * 3600)  # è½¬æ¢ä¸ºå¤©æ•°
            
            return days_diff <= days
        except Exception as e:
            print(f"âš ï¸ Error checking date: {e}")
            return False
    
    def _parse_timestamp(self, date_str: str) -> int:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºæ—¶é—´æˆ³ï¼Œç„¡æ³•è§£ææ™‚è¿”å›0ï¼ˆæœƒè¢«10å¤©éæ¿¾å™¨éæ¿¾æ‰ï¼‰"""
        if not date_str:
            return 0  # æ²’æœ‰æ—¥æœŸ â†’ éæ¿¾æ‰
        
        try:
            # æ¸…ç†å¸¸è¦‹æ™‚å€æ ¼å¼: +0000 â†’ +00:00
            clean_str = date_str.strip()
            import re as _re
            # è™•ç† +0000 æˆ– -0500 ç­‰æ ¼å¼
            tz_match = _re.search(r'([+-])(\d{2})(\d{2})$', clean_str)
            if tz_match and ':' not in clean_str[-6:]:
                clean_str = clean_str[:tz_match.start()] + f"{tz_match.group(1)}{tz_match.group(2)}:{tz_match.group(3)}"
            
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            formats = [
                "%Y-%m-%dT%H:%M:%S.%fZ",
                "%Y-%m-%dT%H:%M:%SZ", 
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d",
                "%a, %d %b %Y %H:%M:%S %Z",
                "%a, %d %b %Y %H:%M:%S %z",
            ]
            
            for fmt in formats:
                try:
                    dt = datetime.strptime(clean_str, fmt)
                    return int(dt.timestamp())
                except ValueError:
                    continue
            
            # å˜—è©¦ ISO æ ¼å¼ï¼ˆå¸¶æ™‚å€ï¼‰
            try:
                dt = datetime.fromisoformat(clean_str.replace('Z', '+00:00'))
                return int(dt.timestamp())
            except (ValueError, AttributeError):
                pass
            
            print(f"âš ï¸ Cannot parse date: {date_str}")
            return 0  # ç„¡æ³•è§£æ â†’ éæ¿¾æ‰
            
        except Exception:
            return 0  # ç•°å¸¸ â†’ éæ¿¾æ‰
    
    def cleanup_cache(self):
        """æ¸…ç†ç·©å­˜å’ŒèˆŠæ•¸æ“š"""
        print("ğŸ§¹ Cleaning up cache...")
        self.sqlite_cache.cleanup_old_cache()
        if self.mongodb:
            self.mongodb.cleanup_old_articles(days=30)
        
    def get_service_stats(self) -> Dict[str, Any]:
        """ç²å–æœå‹™çµ±è¨ˆä¿¡æ¯"""
        auth_status = self.auth.get_status()
        cache_stats = self.sqlite_cache.get_cache_stats()
        
        # MongoDBçµ±è¨ˆ
        if self.mongodb:
            db_stats = self.mongodb.get_stats()
        else:
            db_stats = {"status": "disconnected", "total_articles": 0, "symbol_stats": []}
        
        return {
            "auth": auth_status,
            "cache": cache_stats,
            "database": db_stats,
            "service_status": "running"
        }